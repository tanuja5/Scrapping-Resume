from bs4 import BeautifulSoup
import requests
from bs4 import BeautifulSoup

#link to page with resumes.
r = requests.get("https://www.indeed.com/resumes?q=information+technology&l=Bangalore%2C+Karnataka&co=IN&start=300")
soup = BeautifulSoup(r.text, "html.parser")
productDivs = soup.find("ol", {"class": "resultsList"})
resumes = []
for div in productDivs:    
    resumes.append(div.a['href'])
print(resumes)
import csv
with open("newFile2.csv", 'a', encoding='utf-8-sig') as myfile:
    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)
    list = ["link","resumeContract","headline","contactInfo","resSummary","workTitle","workCompany","workDates","workDescr","edTitle","edSkul","edDates","skills","exLinks","addInfo"]
    wr.writerow(list)
    for val in resumes:
        print(val)
        r1 = requests.get("https://www.indeed.com"+ val)
        soup1 = BeautifulSoup(r1.text, "html.parser")
        res_contact = soup1.find("h1", {"id": "resume-contact"})
        res_contact = str(res_contact)
        res_contact = BeautifulSoup(res_contact,"lxml")
        res_contact = (res_contact.get_text())
        res_contact = str(res_contact)
        print(res_contact)
        headline = soup1.find("h2", {"id": "headline"})
        headline = str(headline)
        headline = BeautifulSoup(headline, "lxml")
        headline = (headline.get_text())
        headline = str(headline)
        print(headline)
        contact_info = soup1.find("p", {"id": "headline_location"})
        contact_info = str(contact_info)
        contact_info = BeautifulSoup(contact_info, "lxml")
        contact_info = (contact_info.get_text())
        contact_info = str(contact_info)
        print(contact_info)
        res_summary = soup1.find("p", {"id": "res_summary"})
        res_summary = str(res_summary)
        res_summary = BeautifulSoup(res_summary, "lxml")
        res_summary = (res_summary.get_text())
        res_summary = str(res_summary)
        print(res_summary)
        '''work_experience = soup1.find_all("div", {"id": "work-experience-items"})
        work_experience = str(work_experience)
        work_experience = BeautifulSoup(work_experience, "lxml")
        work_experience = (work_experience.get_text())
        work_experience = str(work_experience)
        print(work_experience)'''
        work_title1 = soup1.find_all("p", {"class": "work_title title"})
        work_title1 = str(work_title1)
        work_title1 = BeautifulSoup(work_title1, "lxml")
        work_title1 = (work_title1.get_text())
        work_title1 = str(work_title1)
        print(work_title1)
        work_comp1 = soup1.find_all('div',attrs={"class":"work_company"})
        work_comp1 = str(work_comp1)
        work_comp1 = BeautifulSoup(work_comp1, "lxml")
        work_comp1 = (work_comp1.get_text())
        work_comp1 = str(work_comp1)
        print(work_comp1)
        work_dates1 = soup1.find_all("p", {"class": "work_dates"})
        work_dates1 = str(work_dates1)
        work_dates1 = BeautifulSoup(work_dates1, "lxml")
        work_dates1 = (work_dates1.get_text())
        work_dates1 = str(work_dates1)
        print(work_dates1)
        work_des1 = soup1.find_all("p", {"class": "work_description"})
        work_des1 = str(work_des1)
        work_des1 = BeautifulSoup(work_des1, "lxml")
        work_des1 = (work_des1.get_text())
        work_des1 = str(work_des1)
        print(work_des1)
        ed_title = soup1.find_all("p", {"class": "edu_title"})
        ed_title = str(ed_title)
        ed_title = BeautifulSoup(ed_title, "lxml")
        ed_title = (ed_title.get_text())
        ed_title = str(ed_title)
        print(ed_title)
        ed_skul = soup1.find_all("div", {"class": "edu_school"})
        ed_skul = str(ed_skul)
        ed_skul = BeautifulSoup(ed_skul, "lxml")
        ed_skul = (ed_skul.get_text())
        ed_skul = str(ed_skul)
        print(ed_skul)
        ed_dates = soup1.find_all("p", {"class": "edu_dates"})
        ed_dates = str(ed_dates)
        ed_dates = BeautifulSoup(ed_dates, "lxml")
        ed_dates = (ed_dates.get_text())
        ed_dates = str(ed_dates)
        print(ed_dates)
        skills = soup1.find_all("span", {"class": "skill-text"})
        skills = str(skills)
        skills = BeautifulSoup(skills, "lxml")
        skills = (skills.get_text())
        skills = str(skills)
        print(skills)
        ex_links = soup1.find_all("p", {"class": "link_url"})
        ex_links = str(ex_links)
        ex_links = BeautifulSoup(ex_links, "lxml")
        ex_links = (ex_links.get_text())
        ex_links = str(ex_links)
        print(ex_links)
        add_info = soup1.find("div", {"id": "additionalinfo-section"})
        add_info = str(add_info)
        add_info = BeautifulSoup(add_info, "lxml")
        add_info = (add_info.get_text())
        add_info = str(add_info)
        print(add_info)
        temp = "https://www.indeed.com"+val
        list1 = [temp,res_contact,headline,contact_info,res_summary,work_title1,work_comp1,work_dates1,work_des1,ed_title,ed_skul,ed_dates,skills,ex_links,add_info]  
        wr.writerow(list1)
